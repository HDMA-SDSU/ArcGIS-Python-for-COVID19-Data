{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly COVID-19 Cases Dashboard Update\n",
    "Center for Human Dynamics in the Mobile Age (HDMA) at San Diego State University\n",
    "\n",
    "Jessica Embury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "from arcgis.gis import GIS\n",
    "from arcgis import geometry\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import webbrowser\n",
    "\n",
    "#ignore pandas slice warning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIRM USER VARIABLES BEFORE RUNNING CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "###SET DATA THROUGH DATE###\n",
    "###########################\n",
    "most_recent_date = '07/06/2021'  # Change date to the data through date using 'MM/DD/YYYY' format\n",
    "\n",
    "\n",
    "##########################\n",
    "###SET PATHS IN AND OUT###\n",
    "##########################\n",
    "#PATHS IN\n",
    "#additional needed zip info - community name and population\n",
    "zips_info_path = './data/zip_coords_pop.csv'\n",
    "\n",
    "#PATHS OUT\n",
    "#wide df with a column for each date\n",
    "wide_df_path = './data/covid_accumulated_formatted.csv'\n",
    "\n",
    "#path out for dash updates, feature layer overwrite\n",
    "path_out= './data/covid_percents_upload.csv'\n",
    "path_out2 = '../covid_data/percents/covid_percents_{}.csv'\n",
    "\n",
    "#path to csv used to append new column to feature layer 2 for cumulative cases dashboard\n",
    "append_csv_path = './data/sd_zip_cumulative_covid_append.csv'\n",
    "\n",
    "#upload to dropbox\n",
    "dropbox_cumulative = 'C:/Users/jesse/Dropbox/Mapping-Vulearable-Pop-Tasks/SD-County-Data/COVID-Data-Share-at-HDMA-Center/SD_Zipcode_COVID_{}.csv'\n",
    "\n",
    "# 7 day dash layer overwrite\n",
    "seven_path = 'sandiego_covid_upload_7day.csv'\n",
    "\n",
    "################################\n",
    "###ARCGIS DETAILS FOR UPDATES###\n",
    "################################\n",
    "\n",
    "#feature layer IDs to overwrite\n",
    "feature_layer2 = '2a2645b5f569461d916122c3e16d96f3'\n",
    "seven_layer = 'f6558646808b4b88ba1d77e984b9f7e8'\n",
    "\n",
    "#csv to append to feature_layer2\n",
    "append_csv = '49be034d6b7a406ca291cb44e94e1be1'\n",
    "\n",
    "#map IDs for symbology update\n",
    "#confirmed cases map\n",
    "cc = \"763a114f5f114139af5517ac4c785bd8\"\n",
    "\n",
    "# seven day maps\n",
    "seven_map = 'cd2e0028e1f049e7bd268d06c26cfe22'\n",
    "seven_map_mobile = 'ee46036487c3491caf69209d2a67940c'\n",
    "\n",
    "#urls for dashboards (to verify)\n",
    "cumulative_dash = 'https://arcg.is/1zXq1m'\n",
    "cumulative_mobile = 'https://arcg.is/1WLnjG'\n",
    "seven_dash = 'https://experience.arcgis.com/experience/a630917e020440ba9a598bf1c32b7a74'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE SD COUNTY COVID-19 PDF FILES TO DROPBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify directory for new folder\n",
    "pdf_path = 'C:/Users/jesse/Dropbox/Mapping-Vulearable-Pop-Tasks/SD-County-Data/{}'.format(most_recent_date.replace('/', '-'))\n",
    "\n",
    "#create folder if it doesn't exist\n",
    "if not os.path.exists(pdf_path):\n",
    "    os.makedirs(pdf_path)\n",
    "\n",
    "#base url for pdfs\n",
    "url = 'https://www.sandiegocounty.gov/content/dam/sdc/hhsa/programs/phs/Epidemiology/'\n",
    "\n",
    "#pdf names\n",
    "pdfs = ['COVID-19%20Percentage%20Positive.pdf', 'COVID-19%20Cases%20by%20Date%20of%20Illness%20Onset.pdf', \n",
    "        'COVID-19%20Daily%20Update_City%20of%20Residence.pdf', 'COVID-19%20City%20of%20Residence_MAP.pdf', \n",
    "        'COVID-19%20Race%20and%20Ethnicity%20Summary.pdf', 'COVID-19%20Summary%20of%20Cases%20by%20Zip%20Code.pdf', \n",
    "        'COVID-19%20Hospitalizations%20by%20Date%20Admitted.pdf', 'COVID-19%20Hospitalizations%20Summary_ALL.pdf', \n",
    "        'COVID-19%20Deaths%20by%20Date%20of%20Death.pdf', 'COVID-19%20Deaths%20by%20Demographics.pdf', \n",
    "        'COVID-19_Daily_Status_Update.pdf', 'COVID-19%20Watch.pdf', 'Summary_County_of_San_Diego_Supported_Tests_by_Race_Ethnicity.pdf',\n",
    "        'Summary_of_All_Tests_Reported_by_Race_Ethnicity.pdf', 'Summary_of_All_Tests_Reported_by_Zip_Code_of_Residence.pdf', \n",
    "        'Summary_Tests_Among_San_Diego_County_Residents_by_Race_Ethnicity.pdf', 'COVID19%20HHSA%20Region%20Dashboard.pdf', \n",
    "        'COVID19%20NORTH%20COASTAL%20Dashboard.pdf', 'COVID19%20NORTH%20INLAND%20Dashboard.pdf', 'COVID19%20NORTH%20CENTRAL%20Dashboard.pdf', \n",
    "        'COVID19%20CENTRAL%20Dashboard.pdf', 'COVID19%20EAST%20Dashboard.pdf', 'COVID19%20SOUTH%20Dashboard.pdf', \n",
    "        'COVID-19%20Vaccinations%20Demographics.pdf', 'COVID-19%20Vaccine%20Report%20by%20Zipcode.pdf',\n",
    "        'Summary_Public_Health_Rooms_by_Race_Ethnicity.pdf', 'COSD_Case_Investigators_by_Race_Ethnicity.pdf', 'COSD_Contact_Tracers_by_Race_Ethnicity.pdf',\n",
    "        'COVID-19%20Variant%20Case%20Summary.pdf', 'COVID-19%20Homeless%20Summary.pdf', 'COVID-19%20Vaccinations%20by%20Health%20Equity%20Zip%20Codes.pdf',\n",
    "        'COVID-19%20Health%20Equity%20Zip%20Codes%20Summary%20and%20Vaccinations%20Report.pdf', 'COVID-19%20Vaccinations%20by%20Census%20Tract.pdf',\n",
    "        'COVID-19%20Vaccinations%20Demographics%20Report%2065%2bResidents.pdf', 'COVID-19%20Deaths%20by%20Zip%20Code.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each pdf in list, get and save\n",
    "for i in range(len(pdfs)):\n",
    "    print(pdfs[i])\n",
    "    response = requests.get(url + pdfs[i], stream=True)\n",
    "\n",
    "    with open(pdf_path + '/' + pdfs[i].replace('%20', ' '), 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "#pdf with a different url\n",
    "response = requests.get(url + '/covid19/MediaBriefingSlides/mediaBriefingSlides.pdf', stream=True)\n",
    "with open(pdf_path + '/' + 'mediaBriefingSlides.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FORMAT CONFIRMED CASES FROM ZIP PDF, SAVE TO CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save info from cumulative case by zip PDF to csv file. Copy/paste data will result in all data in one column.\n",
    "raw = pd.read_csv('./data/zip_cases_raw.csv')\n",
    "\n",
    "# zip code\n",
    "raw1 = raw.iloc[0::3, :].reset_index()\n",
    "print(len(raw1))\n",
    "# vacc count\n",
    "raw2 = raw.iloc[1::3, :].reset_index()\n",
    "print(len(raw2))\n",
    "# rate\n",
    "raw3 = raw.iloc[2::3, :].reset_index()\n",
    "print(len(raw3))\n",
    "\n",
    "# create empty DF\n",
    "cols = ['Zipcode', most_recent_date] \n",
    "t = pd.DataFrame(columns = cols)\n",
    "\n",
    "# add raw data to t data frame\n",
    "for i in range(110):\n",
    "    temp = [raw1['cases'][i], raw2['cases'][i]] \n",
    "    t = t.append({'Zipcode': temp[0], most_recent_date: temp[1]}, ignore_index=True) \n",
    "\n",
    "#format numbers in counts column\n",
    "for i, row in t.iterrows():\n",
    "    t[most_recent_date][i] = t[most_recent_date][i].replace(',', '')\n",
    "    \n",
    "t[most_recent_date] = t[most_recent_date].astype(int)\n",
    "print(type(t[most_recent_date][0]))\n",
    "\n",
    "print(len(t))\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#add new column to csv with all dates\n",
    "wide = pd.read_csv(wide_df_path)\n",
    "wide['Zipcode'] = wide['Zipcode'].astype(str)\n",
    "\n",
    "wide = wide.merge(t, on='Zipcode', how='left')\n",
    "wide[most_recent_date] = wide[most_recent_date].fillna(0)\n",
    "print(len(wide))\n",
    "wide.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save updated table to csv\n",
    "wide.to_csv(wide_df_path, index=False)\n",
    "wide.to_csv(dropbox_cumulative.format(most_recent_date.replace('/', '')), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE WIDE DF WITH COORDINATES/COMMUNITY/POPULATION CSV DATA\n",
    "### SUBSET DF WITH ONLY COLUMNS FOR HDMA RATES/PERCENTS FEATURE LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = pd.read_csv(wide_df_path)\n",
    "wide['Zipcode'] = wide['Zipcode'].astype(str)\n",
    "wide.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import additional needed zip info\n",
    "zips_info = pd.read_csv(zips_info_path)\n",
    "zips_info = zips_info.rename(columns = {'Zip':'Zipcode'})\n",
    "zips_info['Zipcode'] = zips_info['Zipcode'].astype(str)\n",
    "\n",
    "#merge wide df with coords and extra zip code info\n",
    "wide = wide.merge(zips_info, on='Zipcode')\n",
    "\n",
    "#create new df for use feature layer overwrite\n",
    "cols = ['Zipcode', 'Community', 'Latitude', 'Longitude', '2018_population']\n",
    "df = wide[cols]\n",
    "\n",
    "df['Date'] = most_recent_date\n",
    "\n",
    "df['Confirmed Cases'] = wide[most_recent_date]\n",
    "\n",
    "df['Rate Per 100K'] = (df['Confirmed Cases']/df['2018_population']*100000).round(2)\n",
    "\n",
    "df = df.fillna(0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPORARY DF TO CALCULATE CASE INCREASE AND RATES OF CHANGE, MERGE TO MAIN DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DF\n",
    "date_df = wide[['Zipcode', wide.columns[-6], wide.columns[-5]]]\n",
    "\n",
    "#CREATE COLUMN FOR CASE INCREASES (column in feature layer, but no longer used due to weekly update change)\n",
    "date_df['Daily Increased'] = np.nan\n",
    "\n",
    "#CREATE COLUMN FOR DAILY CHANGE RATE (column in feature layer, but no longer used due to weekly update change)\n",
    "date_df['Daily Change Rate*1000'] = np.nan\n",
    "\n",
    "#CREATE COLUMN FOR 7 DAY ROLLING RATE OF CHANGE AND 7 DAY INCREASE COLUMN\n",
    "date_df['7 Days Rolling Change*1000'] = np.nan\n",
    "\n",
    "date_df['7 Day Case Increase'] = date_df.iloc[:,2] - date_df.iloc[:,1]\n",
    "print(date_df['7 Day Case Increase'].sum())\n",
    "\n",
    "#CALCULATE 7 DAY CHANGE RATE\n",
    "try:\n",
    "    date_df['7 Days Rolling Change*1000'] = round(date_df.iloc[:,6]/date_df.iloc[:,1]/7*1000, 2)\n",
    "except:\n",
    "    pass            \n",
    "\n",
    "print(len(date_df))\n",
    "date_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGE WITH MAIN DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE NEW COLUMNS WITH MAIN DF\n",
    "date_df_subset = date_df[['Zipcode', 'Daily Increased', 'Daily Change Rate*1000', '7 Days Rolling Change*1000', '7 Day Case Increase']]\n",
    "\n",
    "df =df.merge(date_df_subset, on='Zipcode')\n",
    "print(len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format conf cases, 7 day increase to int type\n",
    "df['Confirmed Cases'] = df['Confirmed Cases'].astype(int)\n",
    "\n",
    "df['7 Day Case Increase'] = df['7 Day Case Increase'].astype(int)\n",
    "\n",
    "#SUBSET DATA TO POPULATION >= 5000 AND CONFIRMED CASES >= 10\n",
    "df = df[df['2018_population'] >= 5000]\n",
    "df = df[df['Confirmed Cases'] >= 10]\n",
    "print(len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATE NEW/CUMULATIVE CASE PERCENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cumulative case totals for county (after subset)\n",
    "sum_confirmed = df['Confirmed Cases'].sum()\n",
    "print(sum_confirmed)\n",
    "\n",
    "#add new columns and calculate percent of total for each zip code\n",
    "df['percent_total'] = round((df['Confirmed Cases']/sum_confirmed)*100, 2)\n",
    "df['percent_daily'] = np.nan #column in feature layer, but no longer used due to weekly update change\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT CSV FOR RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv files\n",
    "df.to_csv(path_out, index = False) \n",
    "df.to_csv(path_out2.format(most_recent_date.replace('/','')), index = False)\n",
    "df.to_csv(seven_path, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONNECT TO ARCGIS ACCOUNT\n",
    "Reference for authentication schemes: https://developers.arcgis.com/python/guide/working-with-different-authentication-schemes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#gis = GIS(portal, username, password)\n",
    "gis = GIS(\"pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIND MAX/MIN VALUES FOR MAP SYMBOLOGY CHANGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_confirmed = df['Confirmed Cases'].max()\n",
    "max_7day = df['7 Day Case Increase'].max()\n",
    "\n",
    "print(max_confirmed, max_7day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map (map_id):\n",
    "    '''\n",
    "    GET MAP DATA FOR SYMBOLOGY CHANGES\n",
    "    '''\n",
    "    \n",
    "    m = gis.content.get(map_id)\n",
    "\n",
    "    data = m.get_data()\n",
    "    \n",
    "    #Include the below line for prettified JSON\n",
    "    #print(json.dumps(data, indent=4, sort_keys=True))\n",
    "\n",
    "    print(m)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def update_map (map_id, data):\n",
    "    '''\n",
    "    UPDATE MAP TO SAVE CHANGES\n",
    "    '''\n",
    "    m = gis.content.get(map_id)\n",
    "    \n",
    "    # Set the item_properties to include the desired update\n",
    "    properties = {\"text\": json.dumps(data)}\n",
    "\n",
    "    # 'Commit' the updates to the Item\n",
    "    update = m.update(item_properties=properties)\n",
    "    \n",
    "    return update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE CUMULATIVE CASE DASHBOARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPEND DATA TO CUMULATIVE CASES FEATURE LAYER\n",
    "Reference: https://developers.arcgis.com/python/guide/appending-features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature layer containing updated data for maps associated with the CUMULATIVE COVID-19 dashboard\n",
    "layer2 = gis.content.get(feature_layer2)\n",
    "layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all the current fields in the layer so you can use one as a field template.\n",
    "cum_covid_lyr = layer2.layers[0]\n",
    "cum_covid_lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat date for use in appending: append_source = column name in csv, append_field = column name in feature layer, append_alias = column alias\n",
    "split = most_recent_date.split('/')\n",
    "\n",
    "append_source = ''\n",
    "\n",
    "for i in range(len(split)):\n",
    "    if(split[i][0] is '0'):\n",
    "        split[i] = split[i][1:]\n",
    "    if(i == 0):\n",
    "        append_source += split[i]\n",
    "    elif(i == (len(split)-1)): \n",
    "        append_source += '_' + split[i]\n",
    "    else:\n",
    "        append_source += '_' + split[i]\n",
    "\n",
    "append_field = 'F' + append_source\n",
    "append_alias = append_source.replace('_','/')\n",
    "\n",
    "print(append_source, append_field, append_alias)\n",
    "\n",
    "#Create a dictionary from a deep copy of a field in the feature layer, and update the values of this dictionary to reflect a new field.\n",
    "new_field = dict(deepcopy(cum_covid_lyr.properties.fields[5]))\n",
    "new_field['name'] = append_field\n",
    "new_field['alias'] = append_alias\n",
    "new_field['length'] = \"10\"\n",
    "print(new_field)\n",
    "\n",
    "#Update feature layer definition with the new field using the add_to_definition() method.\n",
    "field_list = [new_field]\n",
    "cum_covid_lyr.manager.add_to_definition({\"fields\":field_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only need to add index to 'Zipcode' once - cell kept for reference\n",
    "\n",
    "#Add a unique index to the new attribute field, needed to append\n",
    "#flds = [f.fields.lower() for f in cum_covid_lyr.properties.indexes if f.isUnique]\n",
    "\n",
    "#for fld in cum_covid_lyr.properties.fields:\n",
    "#    if fld.name.lower() in flds:\n",
    "#        print(f\"{fld.name:30}{fld.type:25}isUnique\")\n",
    "#    else:\n",
    "#        print(f\"{fld.name:30}{fld.type:25}\")\n",
    "\n",
    "#Create a copy of one index, then edit it to reflect values for a new index. Then add that to the layer definition.\n",
    "#name_idx = dict(deepcopy(cum_covid_lyr.properties['indexes'][0]))\n",
    "#name_idx['name'] = 'Zipcode'\n",
    "#name_idx['fields'] = 'Zipcode'\n",
    "#name_idx['isUnique'] = True\n",
    "#name_idx['description'] = 'index_name'\n",
    "#name_idx\n",
    "\n",
    "#index_list = [name_idx]\n",
    "#cum_covid_lyr.manager.add_to_definition({\"indexes\":index_list})\n",
    "\n",
    "#Verify the index was added\n",
    "#layer2 = gis.content.get(feature_layer2)\n",
    "#layer2\n",
    "\n",
    "#flds = [f.fields.lower() for f in cum_covid_lyr.properties.indexes if f.isUnique]\n",
    "\n",
    "#for fld in cum_covid_lyr.properties.fields:\n",
    "#    if fld.name.lower() in flds:\n",
    "#        print(f\"{fld.name:30}{fld.type:25}isUnique\")\n",
    "#    else:\n",
    "#        print(f\"{fld.name:30}{fld.type:25}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update csv item to contain new date column for addition to the feature layer\n",
    "append_df2 = wide[['Zipcode', '{}'.format(most_recent_date)]]\n",
    "append_df2 = append_df2.rename(columns = {'{}'.format(most_recent_date): '{}'.format(append_source)})\n",
    "\n",
    "append_df2 = append_df2[append_df2.index.notnull()]\n",
    "append_df2 = append_df2.fillna(0)\n",
    "append_df2['{}'.format(append_source)] = append_df2['{}'.format(append_source)].astype(int)\n",
    "append_df2.to_csv(append_csv_path)\n",
    "\n",
    "append_csv_item = gis.content.get(append_csv)\n",
    "#append_csv_item\n",
    "append_csv_item.update({}, append_csv_path)\n",
    "\n",
    "#get *append_csv_info* when appending a new column for source_info\n",
    "append_csv_info = gis.content.analyze(item=append_csv, file_type='csv', location_type='none')\n",
    "\n",
    "# append_csv_info\n",
    "#append new date column to feature layer from csv item\n",
    "cum_covid_lyr.append(item_id= append_csv,\n",
    "                      upload_format = 'csv',\n",
    "                      field_mappings = [{\"name\":\"{}\".format(append_field), \"source\":\"{}\".format(append_source)},\n",
    "                                        {\"name\":\"Zipcode\", \"source\":\"Zipcode\"}],\n",
    "                      source_info = append_csv_info['publishParameters'],\n",
    "                      update_geometry=False,\n",
    "                      append_fields=[\"{}\".format(append_field), \"Zipcode\"],\n",
    "                      skip_inserts=True,\n",
    "                      upsert_matching_field=\"Zipcode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODIFY CONFIRMED CASES WEB MAP SYMBOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed cases map\n",
    "\n",
    "#get map data\n",
    "cc_data = get_map(cc)\n",
    "\n",
    "#set symbol to new date field, adjust max symbology\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['field'] = append_field\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['field'] = append_field\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_confirmed.item()\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_confirmed.item()\n",
    "\n",
    "#set labeling to new date field\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['labelingInfo'][0]['labelExpressionInfo']['expression'] = '$feature[\"{}\"]'.format(append_field)\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['labelingInfo'][0]['labelExpressionInfo']['value'] = ('{' + append_field + '}')\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['labelingInfo'][0]['fieldInfos'][0]['fieldName'] = append_field\n",
    "\n",
    "#set filter to new date\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['definitionExpression'] = ('{} > 0'.format(append_field))\n",
    "\n",
    "#adjust last date in popup\n",
    "new_date = cc_data['operationalLayers'][2]['popupInfo']['fieldInfos'][-1].copy()\n",
    "new_date['fieldName'] = append_field\n",
    "new_date['label'] = append_alias\n",
    "cc_data['operationalLayers'][2]['popupInfo']['fieldInfos'][-1]['visible'] = False\n",
    "cc_data['operationalLayers'][2]['popupInfo']['fieldInfos'].append(new_date)\n",
    "#cc_data['operationalLayers'][2]['popupInfo']['fieldInfos']\n",
    "\n",
    "#add new date to popup chart\n",
    "popup_chart=cc_data['operationalLayers'][2]['popupInfo']['mediaInfos'][0]['value']['fields']\n",
    "popup_chart.append(append_field)\n",
    "cc_data['operationalLayers'][2]['popupInfo']['mediaInfos'][0]['value']['fields'] = popup_chart\n",
    "\n",
    "#update map to save changes\n",
    "cc_update = update_map(cc, cc_data)\n",
    "cc_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE 7 DAY DASHBOARD\n",
    "\n",
    "### OVERWRITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature layer containing updated data for maps associated with the COVID-19 dashboards\n",
    "layer = gis.content.get(seven_layer)\n",
    "layer\n",
    "\n",
    "layer_collection = FeatureLayerCollection.fromitem(layer)\n",
    "\n",
    "#call the overwrite() method which can be accessed using the manager property\n",
    "layer_collection.manager.overwrite(seven_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP SYMBOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seven day map\n",
    "\n",
    "#get map data\n",
    "sm_data = get_map(seven_map)\n",
    "\n",
    "#adjust symbology for graduated points to reflect new max/min\n",
    "#MAX DAILY INCREASE\n",
    "sm_data['operationalLayers'][4]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7day.item()\n",
    "sm_data['operationalLayers'][4]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7day.item()\n",
    "\n",
    "sm_data['operationalLayers'][5]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7day.item()\n",
    "sm_data['operationalLayers'][5]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7day.item()\n",
    "\n",
    "#update map to save changes\n",
    "sm_update = update_map(seven_map, sm_data)\n",
    "sm_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seven day map mobile\n",
    "\n",
    "#get map data\n",
    "smm_data = get_map(seven_map_mobile)\n",
    "\n",
    "#adjust symbology for graduated points to reflect new max/min\n",
    "#MAX DAILY INCREASE\n",
    "smm_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7day.item()\n",
    "smm_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7day.item()\n",
    "\n",
    "smm_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7day.item()\n",
    "smm_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7day.item()\n",
    "\n",
    "#update map to save changes\n",
    "smm_update = update_map(seven_map_mobile, smm_data)\n",
    "smm_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIEW UPDATED DASHBOARDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open cumulative/growth chart map\n",
    "webbrowser.open(cumulative_dash, new=2)\n",
    "\n",
    "#open seven day cases dash\n",
    "webbrowser.open(seven_dash, new=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
