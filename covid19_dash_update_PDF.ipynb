{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Dashboard Updates\n",
    "Center for Human Dynamics in the Mobile Age (HDMA) at San Diego State University\n",
    "\n",
    "Jessica Embury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "#import arcgis\n",
    "from arcgis.gis import GIS\n",
    "from arcgis import geometry\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "from arcgis.features import FeatureLayer\n",
    "#from arcgis.mapping import WebMap\n",
    "\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import tabula\n",
    "import time\n",
    "import webbrowser\n",
    "\n",
    "#ignore pandas slice warning\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIRM USER VARIABLES BEFORE RUNNING CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "###SET DATA THROUGH DATE###\n",
    "###########################\n",
    "most_recent_date = '02/23/2021'  # Change date daily using 'MM/DD/YYYY' format\n",
    "\n",
    "\n",
    "##########################\n",
    "###SET PATHS IN AND OUT###\n",
    "##########################\n",
    "#PATHS IN\n",
    "#additional needed zip info - community name and population\n",
    "zips_info_path = './data/zip_coords_pop.csv'\n",
    "\n",
    "#PATHS OUT\n",
    "#wide df with a column for each date\n",
    "wide_df_path = './data/covid_accumulated_formatted.csv'\n",
    "\n",
    "#path out for dash updates, feature layer overwrite\n",
    "path_out= './data/covid_percents_upload.csv'\n",
    "path_out2 = '../covid_data/percents/covid_percents_{}.csv'\n",
    "\n",
    "#path to csv used to append new column to feature layer 2 for cumulative cases dashboard\n",
    "append_csv_path = './data/sd_zip_cumulative_covid_append.csv'\n",
    "\n",
    "#upload to dropbox\n",
    "dropbox_cumulative = 'C:/Users/jesse/Dropbox/Mapping-Vulearable-Pop-Tasks/SD-County-Data/COVID-Data-Share-at-HDMA-Center/SD_Zipcode_COVID_{}.csv'\n",
    "\n",
    "# 7 day dash layer overwrite\n",
    "seven_path = 'sandiego_covid_upload_7day.csv'\n",
    "\n",
    "################################\n",
    "###ARCGIS DETAILS FOR UPDATES###\n",
    "################################\n",
    "#URL TO SD COUNTY'S COVID-19 FEATURE SERVICE\n",
    "sd_dashboard_service = 'https://services1.arcgis.com/1vIhDJwtG5eNmiqX/ArcGIS/rest/services/CovidDashUpdate/FeatureServer'\n",
    "\n",
    "#feature layer ID to overwrite\n",
    "feature_layer = \"65333d10997d4eb7bf921e11472ae35d\"\n",
    "feature_layer2 = '2a2645b5f569461d916122c3e16d96f3'\n",
    "\n",
    "#csv to append to feature_layer2\n",
    "append_csv = '49be034d6b7a406ca291cb44e94e1be1'\n",
    "\n",
    "#map IDs for symbology update\n",
    "#heatmaps\n",
    "hm1 = \"3bb63e3ff08243cebf465919191863a0\"\n",
    "hm2 = \"2c8a7e1fe2114bfea6317ae4c3268514\"\n",
    "\n",
    "#rates maps\n",
    "rc1 = \"81ff6fce8f7840f8818ae1651db49fc7\"\n",
    "rc2 = \"f0d7afc488ae4d048c2413159ab70921\"\n",
    "rc3 = \"a24f481d8e954411a40d6b9a18465f86\"\n",
    "rc4 = \"a9fe5732f5ac4ac395f66bdd2275d2ec\"\n",
    "\n",
    "#confirmed cases map\n",
    "cc = \"763a114f5f114139af5517ac4c785bd8\"\n",
    "\n",
    "# seven day data and maps\n",
    "seven_layer = 'f6558646808b4b88ba1d77e984b9f7e8'\n",
    "seven_map = 'cd2e0028e1f049e7bd268d06c26cfe22'\n",
    "seven_map_mobile = 'ee46036487c3491caf69209d2a67940c'\n",
    "\n",
    "#urls for dashboards (to verify)\n",
    "heatmap_dash = 'https://arcg.is/1br8v9'\n",
    "rates_dash = 'https://arcg.is/0Gy0mj'\n",
    "cumulative_dash = 'https://arcg.is/1zXq1m'\n",
    "cumulative_mobile = 'https://arcg.is/1WLnjG'\n",
    "seven_dash = 'https://experience.arcgis.com/experience/a630917e020440ba9a598bf1c32b7a74'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE SD COUNTY COVID-19 PDF FILES TO DROPBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check County of SD website for updated PDF\n",
    "webbrowser.open('https://www.sandiegocounty.gov/content/dam/sdc/hhsa/programs/phs/Epidemiology/COVID-19%20Summary%20of%20Cases%20by%20Zip%20Code.pdf', new=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify directory for new folder\n",
    "pdf_path = 'C:/Users/jesse/Dropbox/Mapping-Vulearable-Pop-Tasks/SD-County-Data/{}'.format(most_recent_date.replace('/', '-'))\n",
    "\n",
    "#create folder if it doesn't exist\n",
    "if not os.path.exists(pdf_path):\n",
    "    os.makedirs(pdf_path)\n",
    "\n",
    "#base url for pdfs\n",
    "url = 'https://www.sandiegocounty.gov/content/dam/sdc/hhsa/programs/phs/Epidemiology/'\n",
    "\n",
    "#pdf names\n",
    "pdfs = ['COVID-19%20Percentage%20Positive.pdf', 'COVID-19%20Cases%20by%20Date%20of%20Illness%20Onset.pdf', \n",
    "        'COVID-19%20Daily%20Update_City%20of%20Residence.pdf', 'COVID-19%20City%20of%20Residence_MAP.pdf', \n",
    "        'COVID-19%20Race%20and%20Ethnicity%20Summary.pdf', 'COVID-19%20Summary%20of%20Cases%20by%20Zip%20Code.pdf', \n",
    "        'COVID-19%20Hospitalizations%20by%20Date%20Admitted.pdf', 'COVID-19%20Hospitalizations%20Summary_ALL.pdf', \n",
    "        'COVID-19%20Deaths%20by%20Date%20of%20Death.pdf', 'COVID-19%20Deaths%20by%20Demographics.pdf', \n",
    "        'COVID-19_Daily_Status_Update.pdf', 'COVID-19%20Watch.pdf', 'Summary_County_of_San_Diego_Supported_Tests_by_Race_Ethnicity.pdf',\n",
    "        'Summary_of_All_Tests_Reported_by_Race_Ethnicity.pdf', 'Summary_of_All_Tests_Reported_by_Zip_Code_of_Residence.pdf', \n",
    "        'Summary_Tests_Among_San_Diego_County_Residents_by_Race_Ethnicity.pdf', 'COVID19%20HHSA%20Region%20Dashboard.pdf', \n",
    "        'COVID19%20NORTH%20COASTAL%20Dashboard.pdf', 'COVID19%20NORTH%20INLAND%20Dashboard.pdf', 'COVID19%20NORTH%20CENTRAL%20Dashboard.pdf', \n",
    "        'COVID19%20CENTRAL%20Dashboard.pdf', 'COVID19%20EAST%20Dashboard.pdf', 'COVID19%20SOUTH%20Dashboard.pdf', \n",
    "        'COVID-19%20Vaccinations%20Demographics.pdf', 'COVID-19%20Vaccine%20Report%20by%20Zipcode.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each pdf in list, get and save\n",
    "for i in range(len(pdfs)):\n",
    "    response = requests.get(url + pdfs[i], stream=True)\n",
    "\n",
    "    with open(pdf_path + '/' + pdfs[i].replace('%20', ' '), 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "#pdf with a different url\n",
    "response = requests.get(url + '/covid19/MediaBriefingSlides/mediaBriefingSlides.pdf', stream=True)\n",
    "with open(pdf_path + '/' + 'mediaBriefingSlides.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FORMAT DAILY CONFIRMED CASES BY ZIP PDF, SAVE TO CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read pdf\n",
    "file = '{}/COVID-19 Summary of Cases by Zip Code.pdf'.format(pdf_path)\n",
    "tables = tabula.read_pdf(file, pages = \"all\", multiple_tables = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format 1st column zips\n",
    "t1 = tables[1][[0, 1]]\n",
    "\n",
    "#rename columns\n",
    "t1 = t1.rename(columns = {0: 'Zipcode', 1: most_recent_date})\n",
    "\n",
    "# drop bad rows\n",
    "t1 = t1.drop(t1.index[0])\n",
    "\n",
    "print(len(t1))\n",
    "#t1.head(2)\n",
    "\n",
    "#format 2nd column zips\n",
    "t2 = tables[2][[0, 1]]\n",
    "\n",
    "#rename columns\n",
    "t2 = t2.rename(columns = {0: 'Zipcode', 1: most_recent_date})\n",
    "\n",
    "# drop bad rows\n",
    "t2 = t2.drop(t2.index[[0, 55, 56]])\n",
    "\n",
    "print(len(t2))\n",
    "#t2.head(2)\n",
    "\n",
    "# merge t1 and t2\n",
    "t1 = t1.append(t2, ignore_index=True)\n",
    "print(len(t1))\n",
    "\n",
    "#format numbers in counts column\n",
    "for i, row in t1.iterrows():\n",
    "    t1[most_recent_date][i] = t1[most_recent_date][i].replace(',', '')\n",
    "    \n",
    "t1[most_recent_date] = t1[most_recent_date].astype(int)\n",
    "print(type(t1[most_recent_date][0]))\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#add new column to csv with all dates\n",
    "wide = pd.read_csv(wide_df_path)\n",
    "wide['Zipcode'] = wide['Zipcode'].astype(str)\n",
    "\n",
    "print(len(wide))\n",
    "#wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = wide.merge(t1, on='Zipcode', how='left')\n",
    "wide[most_recent_date] = wide[most_recent_date].fillna(0)\n",
    "print(len(wide))\n",
    "wide.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save updated table to csv\n",
    "wide.to_csv(wide_df_path, index=False)\n",
    "wide.to_csv(dropbox_cumulative.format(most_recent_date.replace('/', '')), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE WIDE DF WITH COORDINATES/COMMUNITY/POPULATION CSV DATA\n",
    "### SUBSET DF WITH ONLY COLUMNS FOR HDMA RATES/PERCENTS FEATURE LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide = pd.read_csv(wide_df_path)\n",
    "wide['Zipcode'] = wide['Zipcode'].astype(str)\n",
    "#wide.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import additional needed zip info\n",
    "zips_info = pd.read_csv(zips_info_path)\n",
    "zips_info = zips_info.rename(columns = {'Zip':'Zipcode'})\n",
    "zips_info['Zipcode'] = zips_info['Zipcode'].astype(str)\n",
    "\n",
    "#merge wide df with coords and extra zip code info\n",
    "wide = wide.merge(zips_info, on='Zipcode')\n",
    "\n",
    "#create new df for use feature layer overwrite\n",
    "cols = ['Zipcode', 'Community', 'Latitude', 'Longitude', '2018_population']\n",
    "df = wide[cols]\n",
    "\n",
    "df['Date'] = most_recent_date\n",
    "\n",
    "df['Confirmed Cases'] = wide[most_recent_date]\n",
    "\n",
    "df['Rate Per 100K'] = (df['Confirmed Cases']/df['2018_population']*100000).round(2)\n",
    "\n",
    "df = df.fillna(0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMPORARY DF TO CALCULATE CASE INCREASE AND RATES OF CHANGE, MERGE TO MAIN DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGULAR VERSION\n",
    "Data reported for each of the last 8 days. Use 8 columns for 7-day calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DF\n",
    "date_df = wide[['Zipcode', wide.columns[-12], wide.columns[-11], wide.columns[-10], wide.columns[-9], wide.columns[-8], wide.columns[-7], wide.columns[-6], wide.columns[-5]]]\n",
    "\n",
    "#CREATE COLUMN FOR CASE INCREASES AND CALCULATE\n",
    "date_df['Daily Increased'] = date_df.iloc[:,8] - date_df.iloc[:,7] \n",
    "\n",
    "#CREATE COLUMN FOR DAILY CHANGE RATE AND CALCULATE\n",
    "date_df['Daily Change Rate*1000'] = np.nan\n",
    "\n",
    "try:\n",
    "    date_df['Daily Change Rate*1000'] = round(date_df.iloc[:,9]/date_df.iloc[:,7]*1000, 2)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#CREATE COLUMN FOR 7 DAY ROLLING RATE OF CHANGE AND CALCULATE\n",
    "date_df['7 Days Rolling Change*1000'] = 0.0\n",
    "\n",
    "rolling_rate_day_list_cols = [[8,7],[7,6],[6,5],[5,4],[4,3],[3,2],[2,1]]\n",
    "\n",
    "for i, row in date_df.iterrows():\n",
    "    all_days=0\n",
    "    \n",
    "    for x in range(len(rolling_rate_day_list_cols)):\n",
    "        day1 = int(date_df.iloc[:,rolling_rate_day_list_cols[x][0]][i])\n",
    "        day2 = int(date_df.iloc[:,rolling_rate_day_list_cols[x][1]][i])\n",
    "\n",
    "        if(day2 != 0):\n",
    "            one_day = ((day1 - day2)/day2)*1000\n",
    "            all_days = all_days + one_day\n",
    "           \n",
    "    date_df['7 Days Rolling Change*1000'][i] = round(all_days/len(rolling_rate_day_list_cols), 2)\n",
    "    \n",
    "# create column for 7 day case increase and calculate\n",
    "date_df['7 Day Case Increase'] = date_df.iloc[:,8] - date_df.iloc[:,1]\n",
    "\n",
    "date_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# HOLIDAY VERSION\n",
    "Data not reported by County of San Diego on holidays. 2 days of data is reported the following day. 7-day calculations using 7 columns rather than 8 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#CREATE DF\n",
    "#date_df = wide[['Zipcode', wide.columns[-11], wide.columns[-10], wide.columns[-9], wide.columns[-8], wide.columns[-7], wide.columns[-6], wide.columns[-5]]]\n",
    "\n",
    "#CREATE COLUMN FOR CASE INCREASES AND CALCULATE\n",
    "#date_df['Daily Increased'] = date_df.iloc[:,7] - date_df.iloc[:,6]\n",
    "\n",
    "#CREATE COLUMN FOR DAILY CHANGE RATE AND CALCULATE\n",
    "#date_df['Daily Change Rate*1000'] = np.nan\n",
    "\n",
    "#try:\n",
    "#    date_df['Daily Change Rate*1000'] = round(date_df.iloc[:,8]/date_df.iloc[:,6]*1000, 2)\n",
    "#except:\n",
    "#    pass\n",
    "\n",
    "#CREATE COLUMN FOR 7 DAY ROLLING RATE OF CHANGE AND CALCULATE\n",
    "#date_df['7 Days Rolling Change*1000'] = 0.0\n",
    "\n",
    "#rolling_rate_day_list_cols = [[7,6],[6,5],[5,4],[4,3],[3,2],[2,1]]\n",
    "\n",
    "#for i, row in date_df.iterrows():\n",
    "    all_days=0\n",
    "    \n",
    "#    for x in range(len(rolling_rate_day_list_cols)):\n",
    "#        day1 = int(date_df.iloc[:,rolling_rate_day_list_cols[x][0]][i])\n",
    "#        day2 = int(date_df.iloc[:,rolling_rate_day_list_cols[x][1]][i])\n",
    "\n",
    "#        if(day2 != 0):\n",
    "#            one_day = ((day1 - day2)/day2)*1000\n",
    "#            all_days = all_days + one_day\n",
    "           \n",
    "#    date_df['7 Days Rolling Change*1000'][i] = round(all_days/7, 2)\n",
    "\n",
    "# create column for 7 day case increase and calculate\n",
    "#date_df['7 Day Case Increase'] = date_df.iloc[:,7] - date_df.iloc[:,1]\n",
    "\n",
    "#date_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGE WITH MAIN DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE NEW COLUMNS WITH MAIN DF\n",
    "date_df_subset = date_df[['Zipcode', 'Daily Increased', 'Daily Change Rate*1000', '7 Days Rolling Change*1000', '7 Day Case Increase']]\n",
    "\n",
    "df =df.merge(date_df_subset, on='Zipcode')\n",
    "print(len(df))\n",
    "\n",
    "#format conf cases, daily increase, 7 day increase to int type\n",
    "df['Confirmed Cases'] = round(df['Confirmed Cases'], 0)\n",
    "df['Confirmed Cases'] = df['Confirmed Cases'].astype(int)\n",
    "\n",
    "df['Daily Increased'] = round(df['Daily Increased'], 0)\n",
    "df['Daily Increased'] = df['Daily Increased'].astype(int)\n",
    "\n",
    "df['7 Day Case Increase'] = round(df['7 Day Case Increase'], 0)\n",
    "df['7 Day Case Increase'] = df['7 Day Case Increase'].astype(int)\n",
    "\n",
    "#SUBSET DATA TO POPULATION >= 5000 AND CONFIRMED CASES >= 10\n",
    "df = df[df['2018_population'] >= 5000]\n",
    "df = df[df['Confirmed Cases'] >= 10]\n",
    "print(len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULATE NEW/CUMULATIVE CASE PERCENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cumulative case and daily increase totals for county (after subset)\n",
    "sum_confirmed = df['Confirmed Cases'].sum()\n",
    "sum_daily = df['Daily Increased'].sum()\n",
    "\n",
    "print(sum_confirmed, sum_daily)\n",
    "\n",
    "#add new columns and calculate percent of total and percent of daily new for each zip code\n",
    "df['percent_total'] = round((df['Confirmed Cases']/sum_confirmed)*100, 2)\n",
    "df['percent_daily'] = round((df['Daily Increased']/sum_daily)*100, 2)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUTPUT CSV FOR RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv files\n",
    "df.to_csv(path_out, index = False) \n",
    "df.to_csv(path_out2.format(most_recent_date.replace('/','')), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONNECT TO ARCGIS ACCOUNT\n",
    "Reference for authentication schemes: https://developers.arcgis.com/python/guide/working-with-different-authentication-schemes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gis = GIS(portal, username, password)\n",
    "gis = GIS(\"pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIND MAX/MIN VALUES FOR MAP SYMBOLOGY CHANGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_confirmed = df['Confirmed Cases'].max()\n",
    "\n",
    "max_increased = df['Daily Increased'].max()\n",
    "max_decreased = 0 - max_increased\n",
    "\n",
    "min_rate100k = df['Rate Per 100K'].min()\n",
    "max_rate100k = df['Rate Per 100K'].max()\n",
    "\n",
    "min_7dayrate = df['7 Days Rolling Change*1000'].min()\n",
    "max_7dayrate = df['7 Days Rolling Change*1000'].max()\n",
    "\n",
    "max_7day = df['7 Day Case Increase'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map (map_id):\n",
    "    '''\n",
    "    GET MAP DATA FOR SYMBOLOGY CHANGES\n",
    "    '''\n",
    "    \n",
    "    m = gis.content.get(map_id)\n",
    "\n",
    "    data = m.get_data()\n",
    "    \n",
    "    #Include the below line for prettified JSON\n",
    "    #print(json.dumps(data, indent=4, sort_keys=True))\n",
    "\n",
    "    print(m)\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def update_map (map_id, data):\n",
    "    '''\n",
    "    UPDATE MAP TO SAVE CHANGES\n",
    "    '''\n",
    "    m = gis.content.get(map_id)\n",
    "    \n",
    "    # Set the item_properties to include the desired update\n",
    "    properties = {\"text\": json.dumps(data)}\n",
    "\n",
    "    # 'Commit' the updates to the Item\n",
    "    update = m.update(item_properties=properties)\n",
    "    \n",
    "    return update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE RATES AND HEATMAP DASHBOARDS\n",
    "\n",
    "### FEATURE LAYER OVERWRITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature layer containing updated data for maps associated with the COVID-19 dashboards\n",
    "layer = gis.content.get(feature_layer)\n",
    "layer\n",
    "\n",
    "layer_collection = FeatureLayerCollection.fromitem(layer)\n",
    "\n",
    "#call the overwrite() method which can be accessed using the manager property\n",
    "layer_collection.manager.overwrite(path_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RATES OF CHANGE DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rates map1: confirmed cases\n",
    "\n",
    "#get map data\n",
    "rc1_data = get_map(rc1)\n",
    "\n",
    "#adjust symbology for graduated points to reflect new max/min\n",
    "#MAX CONFIRMED\n",
    "rc1_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_confirmed.item()\n",
    "rc1_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_confirmed.item()\n",
    "\n",
    "#MAX CONFIRMED\n",
    "rc1_data['operationalLayers'][4]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_confirmed.item()\n",
    "rc1_data['operationalLayers'][4]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_confirmed.item()\n",
    "\n",
    "#update map to save changes\n",
    "rc1_update = update_map(rc1, rc1_data)\n",
    "rc1_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rates map2: daily case increases\n",
    "\n",
    "#get map data\n",
    "rc2_data = get_map(rc2)\n",
    "\n",
    "#adjust symbology for graduated points to reflect new max/min\n",
    "#MAX DAILY INCREASE\n",
    "rc2_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_increased.item()\n",
    "rc2_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_increased.item()\n",
    "\n",
    "#MAX DAILY INCREASE\n",
    "rc2_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_increased.item()\n",
    "rc2_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_increased.item()\n",
    "\n",
    "#update map to save changes\n",
    "rc2_update = update_map(rc2, rc2_data)\n",
    "rc2_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rates map3: cases per 100k residents\n",
    "\n",
    "#get map data\n",
    "rc3_data = get_map(rc3)\n",
    "\n",
    "#adjust symbology for graduated points to reflect new max/min\n",
    "#MAX RATE PER 100K\n",
    "rc3_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_rate100k.item()\n",
    "rc3_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_rate100k.item()\n",
    "\n",
    "#MIN RATE PER 100K\n",
    "rc3_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['minSliderValue'] = min_rate100k.item()\n",
    "rc3_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['minDataValue'] = min_rate100k.item()\n",
    "\n",
    "#MAX RATE PER 100K\n",
    "rc3_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_rate100k.item()\n",
    "rc3_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_rate100k.item()\n",
    "\n",
    "#MIN RATE PER 100K\n",
    "rc3_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['minSliderValue'] = min_rate100k.item()\n",
    "rc3_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['minDataValue'] = min_rate100k.item()\n",
    "\n",
    "#update map to save changes\n",
    "rc3_update = update_map(rc3, rc3_data)\n",
    "rc3_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rates map4: 7 day rolling rate of change\n",
    "\n",
    "#get map data\n",
    "rc4_data = get_map(rc4)\n",
    "\n",
    "#adjust symbology for graduated points to reflect new max/min\n",
    "#MAX 7 DAY RATE\n",
    "rc4_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7dayrate.item()\n",
    "rc4_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7dayrate.item()\n",
    "\n",
    "#MIN 7 DAY RATE\n",
    "rc4_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['minSliderValue'] = min_7dayrate.item()\n",
    "rc4_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['minDataValue'] = min_7dayrate.item()\n",
    "\n",
    "#MAX 7 DAY RATE\n",
    "rc4_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7dayrate.item()\n",
    "rc4_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7dayrate.item()\n",
    "\n",
    "#MIN 7 DAY RATE\n",
    "rc4_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['minSliderValue'] = min_7dayrate.item()\n",
    "rc4_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['minDataValue'] = min_7dayrate.item()\n",
    "\n",
    "#update map to save changes\n",
    "rc4_update = update_map(rc4, rc4_data)\n",
    "rc4_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HEATMAPS DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap1: daily case increases\n",
    "\n",
    "#get map data\n",
    "hm1_data = get_map(hm1)\n",
    "\n",
    "#adjust symbology for graduated points to reflect new max/min\n",
    "#DAILY INCREASED POINTS\n",
    "hm1_data['operationalLayers'][9]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_increased.item()\n",
    "hm1_data['operationalLayers'][9]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_increased.item()\n",
    "\n",
    "#DAILY DECREASED POINTS\n",
    "hm1_data['operationalLayers'][8]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['minSliderValue'] = max_decreased.item()\n",
    "hm1_data['operationalLayers'][8]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['minDataValue'] = max_decreased.item()\n",
    "\n",
    "#update map to save changes\n",
    "hm1_update = update_map(hm1, hm1_data)\n",
    "hm1_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap2: 7 day rolling rate of change\n",
    "\n",
    "#get map data\n",
    "hm2_data = get_map(hm2)\n",
    "\n",
    "#adjust symbology for graduated points to reflect new max/min\n",
    "#MAX RATE\n",
    "hm2_data['operationalLayers'][7]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7dayrate.item()\n",
    "hm2_data['operationalLayers'][7]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7dayrate.item()\n",
    "\n",
    "#MIN RATE\n",
    "hm2_data['operationalLayers'][7]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['minSliderValue'] = min_7dayrate.item()\n",
    "hm2_data['operationalLayers'][7]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['minDataValue'] = min_7dayrate.item()\n",
    "\n",
    "#update map to save changes\n",
    "hm2_update = update_map(hm2, hm2_data)\n",
    "hm2_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE CUMULATIVE CASE DASHBOARD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPEND DATA TO CUMULATIVE CASES FEATURE LAYER\n",
    "Reference: https://developers.arcgis.com/python/guide/appending-features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature layer containing updated data for maps associated with the CUMULATIVE COVID-19 dashboard\n",
    "layer2 = gis.content.get(feature_layer2)\n",
    "layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all the current fields in the layer so you can use one as a field template.\n",
    "cum_covid_lyr = layer2.layers[0]\n",
    "cum_covid_lyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reformat date for use in appending: append_source = column name in csv, append_field = column name in feature layer, append_alias = column alias\n",
    "split = most_recent_date.split('/')\n",
    "\n",
    "append_source = ''\n",
    "\n",
    "for i in range(len(split)):\n",
    "    if(split[i][0] is '0'):\n",
    "        split[i] = split[i][1:]\n",
    "    if(i == 0):\n",
    "        append_source += split[i]\n",
    "    elif(i == (len(split)-1)): \n",
    "        append_source += '_' + split[i]\n",
    "    else:\n",
    "        append_source += '_' + split[i]\n",
    "\n",
    "append_field = 'F' + append_source\n",
    "append_alias = append_source.replace('_','/')\n",
    "\n",
    "print(append_source, append_field, append_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary from a deep copy of a field in the feature layer, and update the values of this dictionary to reflect a new field.\n",
    "new_field = dict(deepcopy(cum_covid_lyr.properties.fields[5]))\n",
    "new_field['name'] = append_field\n",
    "new_field['alias'] = append_alias\n",
    "new_field['length'] = \"10\"\n",
    "print(new_field)\n",
    "\n",
    "#Update feature layer definition with the new field using the add_to_definition() method.\n",
    "field_list = [new_field]\n",
    "cum_covid_lyr.manager.add_to_definition({\"fields\":field_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only need to add index to 'Zipcode' once - cell kept for reference\n",
    "\n",
    "#Add a unique index to the new attribute field, needed to append\n",
    "#flds = [f.fields.lower() for f in cum_covid_lyr.properties.indexes if f.isUnique]\n",
    "\n",
    "#for fld in cum_covid_lyr.properties.fields:\n",
    "#    if fld.name.lower() in flds:\n",
    "#        print(f\"{fld.name:30}{fld.type:25}isUnique\")\n",
    "#    else:\n",
    "#        print(f\"{fld.name:30}{fld.type:25}\")\n",
    "\n",
    "#Create a copy of one index, then edit it to reflect values for a new index. Then add that to the layer definition.\n",
    "#name_idx = dict(deepcopy(cum_covid_lyr.properties['indexes'][0]))\n",
    "#name_idx['name'] = 'Zipcode'\n",
    "#name_idx['fields'] = 'Zipcode'\n",
    "#name_idx['isUnique'] = True\n",
    "#name_idx['description'] = 'index_name'\n",
    "#name_idx\n",
    "\n",
    "#index_list = [name_idx]\n",
    "#cum_covid_lyr.manager.add_to_definition({\"indexes\":index_list})\n",
    "\n",
    "#Verify the index was added\n",
    "#layer2 = gis.content.get(feature_layer2)\n",
    "#layer2\n",
    "\n",
    "#flds = [f.fields.lower() for f in cum_covid_lyr.properties.indexes if f.isUnique]\n",
    "\n",
    "#for fld in cum_covid_lyr.properties.fields:\n",
    "#    if fld.name.lower() in flds:\n",
    "#        print(f\"{fld.name:30}{fld.type:25}isUnique\")\n",
    "#    else:\n",
    "#        print(f\"{fld.name:30}{fld.type:25}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update csv item to contain new date column for addition to the feature layer\n",
    "append_df2 = wide[['Zipcode', '{}'.format(most_recent_date)]]\n",
    "append_df2 = append_df2.rename(columns = {'{}'.format(most_recent_date): '{}'.format(append_source)})\n",
    "\n",
    "append_df2 = append_df2[append_df2.index.notnull()]\n",
    "append_df2 = append_df2.fillna(0)\n",
    "append_df2['{}'.format(append_source)] = append_df2['{}'.format(append_source)].astype(int)\n",
    "append_df2.to_csv(append_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_csv_item = gis.content.get(append_csv)\n",
    "#append_csv_item\n",
    "append_csv_item.update({}, append_csv_path)\n",
    "\n",
    "#get *append_csv_info* when appending a new column for source_info\n",
    "append_csv_info = gis.content.analyze(item=append_csv, file_type='csv', location_type='none')\n",
    "# append_csv_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append new date column to feature layer from csv item\n",
    "cum_covid_lyr.append(item_id= append_csv,\n",
    "                      upload_format = 'csv',\n",
    "                      field_mappings = [{\"name\":\"{}\".format(append_field), \"source\":\"{}\".format(append_source)},\n",
    "                                        {\"name\":\"Zipcode\", \"source\":\"Zipcode\"}],\n",
    "                      source_info = append_csv_info['publishParameters'],\n",
    "                      update_geometry=False,\n",
    "                      append_fields=[\"{}\".format(append_field), \"Zipcode\"],\n",
    "                      skip_inserts=True,\n",
    "                      upsert_matching_field=\"Zipcode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODIFY CONFIRMED CASES WEB MAP SYMBOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirmed cases map\n",
    "\n",
    "#get map data\n",
    "cc_data = get_map(cc)\n",
    "\n",
    "#set symbol to new date field, adjust max symbology\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['field'] = append_field\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['field'] = append_field\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_confirmed.item()\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_confirmed.item()\n",
    "\n",
    "#set labeling to new date field\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['labelingInfo'][0]['labelExpressionInfo']['expression'] = '$feature[\"{}\"]'.format(append_field)\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['labelingInfo'][0]['labelExpressionInfo']['value'] = ('{' + append_field + '}')\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['labelingInfo'][0]['fieldInfos'][0]['fieldName'] = append_field\n",
    "\n",
    "#set filter to new date\n",
    "cc_data['operationalLayers'][2]['layerDefinition']['definitionExpression'] = ('{} > 0'.format(append_field))\n",
    "\n",
    "#adjust last date in popup\n",
    "new_date = cc_data['operationalLayers'][2]['popupInfo']['fieldInfos'][-1].copy()\n",
    "new_date['fieldName'] = append_field\n",
    "new_date['label'] = append_alias\n",
    "cc_data['operationalLayers'][2]['popupInfo']['fieldInfos'][-1]['visible'] = False\n",
    "cc_data['operationalLayers'][2]['popupInfo']['fieldInfos'].append(new_date)\n",
    "#cc_data['operationalLayers'][2]['popupInfo']['fieldInfos']\n",
    "\n",
    "#add new date to popup chart\n",
    "popup_chart=cc_data['operationalLayers'][2]['popupInfo']['mediaInfos'][0]['value']['fields']\n",
    "popup_chart.append(append_field)\n",
    "cc_data['operationalLayers'][2]['popupInfo']['mediaInfos'][0]['value']['fields'] = popup_chart\n",
    "\n",
    "#update map to save changes\n",
    "cc_update = update_map(cc, cc_data)\n",
    "cc_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE 7 DAY DASHBOARD\n",
    "\n",
    "### OVERWRITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature layer containing updated data for maps associated with the COVID-19 dashboards\n",
    "layer = gis.content.get(seven_layer)\n",
    "layer\n",
    "\n",
    "layer_collection = FeatureLayerCollection.fromitem(layer)\n",
    "\n",
    "#call the overwrite() method which can be accessed using the manager property\n",
    "layer_collection.manager.overwrite(path_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP SYMBOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seven day map\n",
    "\n",
    "#get map data\n",
    "sm_data = get_map(seven_map)\n",
    "\n",
    "#adjust symbology for graduated points to reflect new max/min\n",
    "#MAX DAILY INCREASE\n",
    "sm_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7day.item()\n",
    "sm_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7day.item()\n",
    "\n",
    "sm_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7day.item()\n",
    "sm_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7day.item()\n",
    "\n",
    "#update map to save changes\n",
    "sm_update = update_map(seven_map, sm_data)\n",
    "sm_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seven day map mobile\n",
    "\n",
    "#get map data\n",
    "smm_data = get_map(seven_map_mobile)\n",
    "\n",
    "#adjust symbology for graduated points to reflect new max/min\n",
    "#MAX DAILY INCREASE\n",
    "smm_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7day.item()\n",
    "smm_data['operationalLayers'][2]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7day.item()\n",
    "\n",
    "smm_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['authoringInfo']['visualVariables'][0]['maxSliderValue'] = max_7day.item()\n",
    "smm_data['operationalLayers'][3]['layerDefinition']['drawingInfo']['renderer']['visualVariables'][0]['maxDataValue'] = max_7day.item()\n",
    "\n",
    "#update map to save changes\n",
    "smm_update = update_map(seven_map_mobile, smm_data)\n",
    "smm_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIEW UPDATED DASHBOARDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open heatmaps dashboard in browser\n",
    "webbrowser.open(heatmap_dash, new=2)\n",
    "\n",
    "#Open rates of change dashboard in browser\n",
    "webbrowser.open(rates_dash, new=2)\n",
    "\n",
    "#open cumulative/growth chart map\n",
    "webbrowser.open(cumulative_dash, new=2)\n",
    "\n",
    "#open seven day cases dash\n",
    "webbrowser.open(seven_dash, new=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
